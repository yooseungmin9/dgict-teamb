{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68766714-4ed0-4fc9-9546-9c302c154007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.16.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (2.9.0.post0)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Collecting requests-oauthlib<3,>=1.2.0 (from tweepy)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2025.8.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ysu13\\anaconda3\\lib\\site-packages (from python-dateutil) (1.17.0)\n",
      "Downloading tweepy-4.16.0-py3-none-any.whl (98 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "\n",
      "   ---------------------------------------- 0/3 [oauthlib]\n",
      "   ---------------------------------------- 0/3 [oauthlib]\n",
      "   ---------------------------------------- 0/3 [oauthlib]\n",
      "   ---------------------------------------- 0/3 [oauthlib]\n",
      "   ---------------------------------------- 0/3 [oauthlib]\n",
      "   -------------------------- ------------- 2/3 [tweepy]\n",
      "   -------------------------- ------------- 2/3 [tweepy]\n",
      "   -------------------------- ------------- 2/3 [tweepy]\n",
      "   ---------------------------------------- 3/3 [tweepy]\n",
      "\n",
      "Successfully installed oauthlib-3.3.1 requests-oauthlib-2.0.0 tweepy-4.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy pandas python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b2bb45-02fa-44e0-80af-734bc7488514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, math, sys\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import Dict, Iterable, Optional, List\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e862859-8397-43db-864e-8a7434a669eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ì–´(í•„ìš”ì‹œ í‚¤ì›Œë“œ ì¡°ì •): í•œêµ­ì–´ë§Œ, ë¦¬íŠ¸ìœ— ì œì™¸\n",
    "QUERY = '(ê²½ì œë‰´ìŠ¤ OR \"ê²½ì œ ë‰´ìŠ¤\" OR \"ê²½ì œ ê¸°ì‚¬\") lang:ko -is:retweet'\n",
    "\n",
    "# ê¸°ê°„: ìµœê·¼ 12ì‹œê°„(ë ì‹œê°ì€ í˜„ì¬ë³´ë‹¤ 60ì´ˆ ì´ì „ìœ¼ë¡œ ì•ˆì „ ì„¤ì •)\n",
    "END_TIME   = datetime.now(timezone.utc) - timedelta(seconds=60)\n",
    "START_TIME = END_TIME - timedelta(days=3)\n",
    "\n",
    "# ìš”ì²­ëŸ‰ ë³´ìˆ˜ì ìœ¼ë¡œ\n",
    "MAX_TWEETS_TOTAL = 200    # ì´ ìƒí•œ\n",
    "PAGE_SIZE        = 50     # í˜ì´ì§€ë‹¹ ê°œìˆ˜ (ìµœëŒ€ 100ì´ì§€ë§Œ 50ìœ¼ë¡œ ì—¬ìœ )\n",
    "PAGE_SLEEP_SEC   = 1.0    # ê° í˜ì´ì§€ ì‚¬ì´ 1ì´ˆ ìŠ¬ë¦½(ë ˆì´íŠ¸ë¦¬ë°‹ ì™„í™”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b42c4f18-63aa-4380-892e-52d260bf71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸  Now(UTC): 2025-10-14 11:18:56\n",
      "â±ï¸  Now(KST): 2025-10-14 20:18:56\n",
      "ğŸ“…  Window(UTC): 2025-10-11 11:01:08 â†’ 2025-10-14 11:01:08\n",
      "âš™ï¸  Limits: MAX_TWEETS_TOTAL=200, PAGE_SIZE=50, PAGE_SLEEP_SEC=1.0\n",
      "âœ… Probe OK â€” got 10 tweets in this window\n",
      "  sample: ê²½ì œ ë‰´ìŠ¤ ì œê³µ thÃ´ng tin vá» tÃ¬nh hÃ¬nh tÄƒng trÆ°á»Ÿng, Ø§Ù„ØªØ¶Ø®Ù… ÙˆØ§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± ÙˆØ§Ù„ØªØ¬Ø§Ø±Ø©.\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1) ìƒíƒœ ì¶œë ¥ ----------\n",
    "KST = timezone(timedelta(hours=9))\n",
    "print(\"â±ï¸  Now(UTC):\", datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"â±ï¸  Now(KST):\", datetime.now(KST).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"ğŸ“…  Window(UTC):\", START_TIME.strftime(\"%Y-%m-%d %H:%M:%S\"), \"â†’\", END_TIME.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(f\"âš™ï¸  Limits: MAX_TWEETS_TOTAL={MAX_TWEETS_TOTAL}, PAGE_SIZE={PAGE_SIZE}, PAGE_SLEEP_SEC={PAGE_SLEEP_SEC}\")\n",
    "\n",
    "# ---------- 2) í´ë¼ì´ì–¸íŠ¸ ----------\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=False)\n",
    "\n",
    "# ---------- 3) ìœ í‹¸: íŒŒì¼/ì¬ê°œ ----------\n",
    "def iter_jsonl(path: str):\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        return\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "def load_existing_ids(path: str) -> (set, Optional[int]):\n",
    "    \"\"\"ê¸°ì¡´ JSONLì—ì„œ ID ì§‘í•©ê³¼ ìµœëŒ€ ID(since_id) ë°˜í™˜\"\"\"\n",
    "    seen, max_id = set(), None\n",
    "    for obj in iter_jsonl(path):\n",
    "        tid = obj.get(\"id\")\n",
    "        if tid is None:\n",
    "            continue\n",
    "        tid = int(tid)\n",
    "        seen.add(tid)\n",
    "        if max_id is None or tid > max_id:\n",
    "            max_id = tid\n",
    "    return seen, max_id\n",
    "\n",
    "def append_jsonl(path: str, rows: List[Dict]):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def append_csv(path: str, rows: List[Dict]):\n",
    "    if not rows:\n",
    "        return\n",
    "    df = pd.DataFrame(rows)\n",
    "    header = not os.path.exists(path) or os.path.getsize(path) == 0\n",
    "    df.to_csv(path, index=False, mode=\"a\", header=header)\n",
    "\n",
    "# ---------- 4) 1íšŒ í”„ë¡œë¸Œ(ìƒíƒœ ì ê²€ìš©) ----------\n",
    "def one_shot_probe() -> bool:\n",
    "    \"\"\"í† í°/ì¿¼ë¦¬/í•œë„ ìƒíƒœë¥¼ í•œ ë²ˆ ê°€ë³ê²Œ ì ê²€\"\"\"\n",
    "    try:\n",
    "        resp = client.search_recent_tweets(\n",
    "            query=QUERY,\n",
    "            max_results=10,\n",
    "            tweet_fields=[\"created_at\"]\n",
    "        )\n",
    "        cnt = 0 if not resp.data else len(resp.data)\n",
    "        print(f\"âœ… Probe OK â€” got {cnt} tweets in this window\")\n",
    "        if cnt:\n",
    "            print(\"  sample:\", resp.data[0].text[:80].replace(\"\\n\",\" \"))\n",
    "        return True\n",
    "    except tweepy.Unauthorized:\n",
    "        print(\"âŒ 401 Unauthorized â€” Bearer Token í™•ì¸ í•„ìš”\")\n",
    "        return False\n",
    "    except tweepy.TooManyRequests as e:\n",
    "        headers = getattr(e.response, \"headers\", {})\n",
    "        reset = headers.get(\"x-rate-limit-reset\")\n",
    "        print(\"âš ï¸ 429 TooManyRequests (probe)\")\n",
    "        if reset:\n",
    "            reset_dt_utc = datetime.fromtimestamp(int(reset), tz=timezone.utc)\n",
    "            print(\"  reset(UTC):\", reset_dt_utc.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                  \"| reset(KST):\", reset_dt_utc.astimezone(KST).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        else:\n",
    "            print(\"  reset í—¤ë” ì—†ìŒ â€” ì ì‹œ í›„ ì¬ì‹œë„ ê¶Œì¥\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Unexpected error in probe:\", repr(e))\n",
    "        return False\n",
    "\n",
    "probe_ok = one_shot_probe()\n",
    "\n",
    "# ---------- 5) ìˆ˜ì§‘ ----------\n",
    "def polite_sleep_until(reset_ts: int):\n",
    "    \"\"\"x-rate-limit-resetê¹Œì§€ 1ì´ˆ ë‹¨ìœ„ë¡œ ì¹´ìš´íŠ¸ë‹¤ìš´(ì–¸ì œë“  Interrupt ê°€ëŠ¥)\"\"\"\n",
    "    target = datetime.fromtimestamp(reset_ts, tz=timezone.utc)\n",
    "    while True:\n",
    "        now = datetime.now(timezone.utc)\n",
    "        left = (target - now).total_seconds()\n",
    "        if left <= 0:\n",
    "            break\n",
    "        to_sleep = 1 if left > 1 else left\n",
    "        print(f\"\\râ³ rate limitâ€¦ ë‚¨ì€ {int(left)}ì´ˆ\", end=\"\")\n",
    "        time.sleep(to_sleep)\n",
    "    print(\"\\râœ… ì¬ì‹œë„ ì‹œì‘                                                \")\n",
    "\n",
    "def collect_recent_safely():\n",
    "    seen, since_id = load_existing_ids(OUTPUT_JSONL)\n",
    "    print(f\"ğŸ“‚ Resume: existing={len(seen)} rows, since_id={since_id}\")\n",
    "\n",
    "    collected = 0\n",
    "    buf_jsonl: List[Dict] = []\n",
    "    buf_csv:   List[Dict] = []\n",
    "    next_token = None\n",
    "\n",
    "    try:\n",
    "        while collected < MAX_TWEETS_TOTAL:\n",
    "            try:\n",
    "                resp = client.search_recent_tweets(\n",
    "                    query=QUERY,\n",
    "                    start_time=START_TIME.isoformat(),\n",
    "                    end_time=END_TIME.isoformat(),\n",
    "                    max_results=PAGE_SIZE,\n",
    "                    tweet_fields=[\"created_at\",\"lang\",\"public_metrics\",\"source\"],\n",
    "                    expansions=[\"author_id\"],\n",
    "                    user_fields=[\"username\",\"public_metrics\"],\n",
    "                    next_token=next_token,\n",
    "                    since_id=since_id\n",
    "                )\n",
    "            except tweepy.TooManyRequests as e:\n",
    "                print(\"\\nâš ï¸ 429 TooManyRequests\")\n",
    "                headers = getattr(e.response, \"headers\", {})\n",
    "                reset = headers.get(\"x-rate-limit-reset\")\n",
    "                if reset:\n",
    "                    reset_dt_utc = datetime.fromtimestamp(int(reset), tz=timezone.utc)\n",
    "                    print(\"   reset(UTC):\", reset_dt_utc.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                          \"| reset(KST):\", reset_dt_utc.astimezone(KST).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                    polite_sleep_until(int(reset))\n",
    "                    continue\n",
    "                else:\n",
    "                    # í—¤ë”ê°€ ì—†ìœ¼ë©´ 60ì´ˆë§Œ ë³´ìˆ˜ì ìœ¼ë¡œ ëŒ€ê¸°\n",
    "                    for i in range(60, 0, -1):\n",
    "                        print(f\"\\râ³ 60ì´ˆ ëŒ€ê¸°â€¦ {i}s\", end=\"\")\n",
    "                        time.sleep(1)\n",
    "                    print(\"\\râœ… ì¬ì‹œë„ ì‹œì‘                            \")\n",
    "                    continue\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ (Interrupt)\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"âŒ Unexpected error:\", repr(e))\n",
    "                break\n",
    "\n",
    "            if not resp or not resp.data:\n",
    "                print(\"â„¹ï¸ ë” ì´ìƒ ê²°ê³¼ ì—†ìŒ(ì´ ê¸°ê°„/ì¿¼ë¦¬).\")\n",
    "                break\n",
    "\n",
    "            users = {u.id: u for u in (resp.includes.get(\"users\", []) if resp.includes else [])}\n",
    "            new_rows = []\n",
    "            for t in resp.data:\n",
    "                tid = int(t.id)\n",
    "                if tid in seen:\n",
    "                    continue\n",
    "                seen.add(tid)\n",
    "                u = users.get(t.author_id)\n",
    "                new_rows.append({\n",
    "                    \"id\": tid,\n",
    "                    \"date\": t.created_at.isoformat() if t.created_at else None,\n",
    "                    \"text\": t.text,\n",
    "                    \"username\": getattr(u, \"username\", None),\n",
    "                    \"followers\": (getattr(u, \"public_metrics\", {}) or {}).get(\"followers_count\"),\n",
    "                    \"likes\": t.public_metrics.get(\"like_count\", 0) if t.public_metrics else 0,\n",
    "                    \"retweets\": t.public_metrics.get(\"retweet_count\", 0) if t.public_metrics else 0,\n",
    "                    \"replies\": t.public_metrics.get(\"reply_count\", 0) if t.public_metrics else 0,\n",
    "                    \"source\": t.source\n",
    "                })\n",
    "\n",
    "            if new_rows:\n",
    "                buf_jsonl.extend(new_rows)\n",
    "                buf_csv.extend(new_rows)\n",
    "                collected += len(new_rows)\n",
    "                print(f\"ğŸ“¥ ì´ë²ˆ í˜ì´ì§€ ì‹ ê·œ: {len(new_rows)}ê±´ | ëˆ„ì : {collected}/{MAX_TWEETS_TOTAL}\")\n",
    "\n",
    "            # ë°°ì¹˜ ì €ì¥\n",
    "            if len(buf_jsonl) >= 100:\n",
    "                append_jsonl(OUTPUT_JSONL, buf_jsonl)\n",
    "                append_csv(OUTPUT_CSV, buf_csv)\n",
    "                print(f\"ğŸ’¾ ì €ì¥ +{len(buf_jsonl)} (total so far={collected})\")\n",
    "                buf_jsonl.clear(); buf_csv.clear()\n",
    "\n",
    "            # ìƒí•œ ë„ë‹¬ ì‹œ ì¢…ë£Œ\n",
    "            if collected >= MAX_TWEETS_TOTAL:\n",
    "                print(f\"âœ… ìƒí•œ ë„ë‹¬: {MAX_TWEETS_TOTAL}\")\n",
    "                break\n",
    "\n",
    "            next_token = resp.meta.get(\"next_token\")\n",
    "            if not next_token:\n",
    "                print(\"âœ… ë” ê°€ì ¸ì˜¬ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                break\n",
    "\n",
    "            # í˜ì´ì§€ ì‚¬ì´ ì§§ì€ ìŠ¬ë¦½(ë ˆì´íŠ¸ë¦¬ë°‹ ì™„í™” + ì¸í„°ëŸ½íŠ¸ ì¹œí™”)\n",
    "            time.sleep(PAGE_SLEEP_SEC)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ (try/except)\")\n",
    "\n",
    "    finally:\n",
    "        # ë‚¨ì€ ë²„í¼ ì €ì¥\n",
    "        if buf_jsonl:\n",
    "            append_jsonl(OUTPUT_JSONL, buf_jsonl)\n",
    "            append_csv(OUTPUT_CSV, buf_csv)\n",
    "            print(f\"ğŸ’¾ ìµœì¢… ì €ì¥ +{len(buf_jsonl)}\")\n",
    "        print(f\"ğŸ‰ ì¢…ë£Œ. ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì‹ ê·œ ìˆ˜ì§‘: {collected}ê±´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e1b66-c7a6-4cef-8019-9e4be936a7b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6d6264-d544-434a-98a7-72808f8a1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ì–´: ORë¡œ í™•ì¥ ê°€ëŠ¥ (ë¦¬íŠ¸ìœ— ì œì™¸, í•œêµ­ì–´ë§Œ)\n",
    "QUERY = '(\"ê²½ì œ ë‰´ìŠ¤ ì–´ë µë‹¤\" OR \"ê²½ì œ ê¸°ì‚¬ ì–´ë µë‹¤\" OR \"ê²½ì œ ìš©ì–´ ì–´ë µë‹¤\") lang:ko -is:retweet'\n",
    "\n",
    "# ê¸°ê°„: ìµœê·¼ 7ì¼ (end_timeì€ í˜„ì¬ë³´ë‹¤ 60ì´ˆ ì´ì „ìœ¼ë¡œ ì•ˆì „ ì„¤ì •)\n",
    "END_TIME   = datetime.now(timezone.utc) - timedelta(seconds=60)\n",
    "START_TIME = END_TIME - timedelta(days=7)\n",
    "\n",
    "# ìˆ˜ì§‘ í•œë„(ë„ˆë¬´ ì˜¤ë˜ ëŒì§€ ì•Šë„ë¡ ì•ˆì „ ìƒí•œ)\n",
    "MAX_TWEETS_TOTAL = 1000     # ì›í•˜ëŠ” ì´ ìˆ˜ì§‘ ê°œìˆ˜\n",
    "PAGE_SIZE        = 100      # API í—ˆìš© ìµœëŒ€ 100\n",
    "SHORT_SLEEP_SEC  = 1        # ë ˆì´íŠ¸ë¦¬ë°‹ ì‹œ 1ì´ˆ ë‹¨ìœ„ë¡œ ì§§ê²Œ ëŒ€ê¸°(ì¸í„°ëŸ½íŠ¸ ì¹œí™”)\n",
    "\n",
    "# ---------- 1) í´ë¼ì´ì–¸íŠ¸ ----------\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68fd24ee-966f-40ff-84fc-6fba62d07ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 2) ìœ í‹¸: íŒŒì¼/ì¬ê°œ ----------\n",
    "def iter_jsonl(path: str):\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        return\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                yield json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "def load_existing_ids(path: str) -> (set, Optional[int]):\n",
    "    \"\"\"ê¸°ì¡´ JSONLì—ì„œ ID ì§‘í•©ê³¼ ìµœëŒ€ ID(since_id) ë°˜í™˜\"\"\"\n",
    "    seen, max_id = set(), None\n",
    "    for obj in iter_jsonl(path):\n",
    "        tid = obj.get(\"id\")\n",
    "        if tid is None:\n",
    "            continue\n",
    "        seen.add(int(tid))\n",
    "        if max_id is None or int(tid) > max_id:\n",
    "            max_id = int(tid)\n",
    "    return seen, max_id\n",
    "\n",
    "def append_jsonl(path: str, rows: List[Dict]):\n",
    "    if not rows:\n",
    "        return\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def append_csv(path: str, rows: List[Dict]):\n",
    "    if not rows:\n",
    "        return\n",
    "    df = pd.DataFrame(rows)\n",
    "    header = not os.path.exists(path) or os.path.getsize(path) == 0\n",
    "    df.to_csv(path, index=False, mode=\"a\", header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58798433-9c22-437d-b428-5f6f2944125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3) ìˆ˜ì§‘ ì œë„ˆë ˆì´í„° ----------\n",
    "def search_recent_generator(\n",
    "    query: str,\n",
    "    start_time: datetime,\n",
    "    end_time: datetime,\n",
    "    page_size: int = 100,\n",
    "    since_id: Optional[int] = None,\n",
    ") -> Iterable[Dict]:\n",
    "    \"\"\"\n",
    "    Tweepy v2 search_recent_tweets í˜ì´ì§• ì œë„ˆë ˆì´í„°\n",
    "    - ë ˆì´íŠ¸ë¦¬ë°‹ ì‹œ TooManyRequests ìºì¹˜ â†’ 1ì´ˆ ëŒ€ê¸° ë°˜ë³µ (ì–¸ì œë“  Interrupt ê°€ëŠ¥)\n",
    "    - ê° ë°°ì¹˜ í›„ ì¦‰ì‹œ yield\n",
    "    \"\"\"\n",
    "    next_token = None\n",
    "    while True:\n",
    "        try:\n",
    "            resp = client.search_recent_tweets(\n",
    "                query=query,\n",
    "                start_time=start_time.isoformat(),\n",
    "                end_time=end_time.isoformat(),\n",
    "                max_results=page_size,\n",
    "                tweet_fields=[\"created_at\", \"lang\", \"public_metrics\", \"source\", \"context_annotations\", \"in_reply_to_user_id\"],\n",
    "                expansions=[\"author_id\"],\n",
    "                user_fields=[\"username\", \"name\", \"public_metrics\"],\n",
    "                next_token=next_token,\n",
    "                since_id=since_id\n",
    "            )\n",
    "        except tweepy.TooManyRequests as e:\n",
    "            # ë ˆì´íŠ¸ë¦¬ë°‹ â†’ 1ì´ˆ ë‹¨ìœ„ë¡œ ì§§ê²Œ ëŒ€ê¸°í•˜ì—¬ ì–¸ì œë“  Interrupt ê°€ëŠ¥\n",
    "            # (ë‚¨ì€ ì‹œê°„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ì§§ì€ ë£¨í”„ ëŒ€ê¸°)\n",
    "            print(\"âš ï¸ Rate limit hit â†’ short-sleep loopâ€¦ (Ctrl+Cë¡œ ì–¸ì œë“  ì¤‘ë‹¨ ê°€ëŠ¥)\")\n",
    "            try:\n",
    "                # ìµœëŒ€ 15ë¶„ê¹Œì§€ ëŒ€ê¸°(ì§§ê²Œ ëŠì–´ì„œ)\n",
    "                wait_cap = 15 * 60\n",
    "                waited = 0\n",
    "                while waited < wait_cap:\n",
    "                    time.sleep(SHORT_SLEEP_SEC)\n",
    "                    waited += SHORT_SLEEP_SEC\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨(KeyboardInterrupt) â†’ ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ë¶„ë§Œ ë°˜í™˜\")\n",
    "                return\n",
    "            else:\n",
    "                # ëŒ€ê¸° í›„ ì¬ì‹œë„\n",
    "                continue\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨(KeyboardInterrupt) â†’ ì§€ê¸ˆê¹Œì§€ ìˆ˜ì§‘ë¶„ë§Œ ë°˜í™˜\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Unexpected error: {repr(e)}\")\n",
    "            return\n",
    "\n",
    "        if not resp.data:\n",
    "            return\n",
    "\n",
    "        users = {u.id: u for u in (resp.includes.get(\"users\", []) if resp.includes else [])}\n",
    "        batch = []\n",
    "        for t in resp.data:\n",
    "            u = users.get(t.author_id)\n",
    "            item = {\n",
    "                \"id\": int(t.id),\n",
    "                \"date\": t.created_at.isoformat() if t.created_at else None,\n",
    "                \"lang\": t.lang,\n",
    "                \"text\": t.text,\n",
    "                \"author_id\": t.author_id,\n",
    "                \"username\": getattr(u, \"username\", None),\n",
    "                \"name\": getattr(u, \"name\", None),\n",
    "                \"followers\": (getattr(u, \"public_metrics\", {}) or {}).get(\"followers_count\"),\n",
    "                \"retweets\": t.public_metrics.get(\"retweet_count\", 0) if t.public_metrics else None,\n",
    "                \"replies\":  t.public_metrics.get(\"reply_count\", 0) if t.public_metrics else None,\n",
    "                \"likes\":    t.public_metrics.get(\"like_count\", 0) if t.public_metrics else None,\n",
    "                \"quotes\":   t.public_metrics.get(\"quote_count\", 0) if t.public_metrics else None,\n",
    "                \"source\":   t.source,\n",
    "            }\n",
    "            batch.append(item)\n",
    "\n",
    "        for row in batch:\n",
    "            yield row\n",
    "\n",
    "        next_token = resp.meta.get(\"next_token\")\n",
    "        if not next_token:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df825655-2deb-44b0-9ace-6880070dd1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ resume: existing=0 rows, since_id=None\n",
      "âš ï¸ Rate limit hit â†’ short-sleep loopâ€¦ (Ctrl+Cë¡œ ì–¸ì œë“  ì¤‘ë‹¨ ê°€ëŠ¥)\n",
      "âŒ Unexpected error: BadRequest(\"400 Bad Request\\nInvalid 'start_time':'2025-10-07T10:27Z'. 'start_time' must be on or after 2025-10-07T10:42Z\")\n",
      "ğŸ‰ done. total collected in this run: 0\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4) ì‹¤í–‰(ì²´í¬í¬ì¸íŠ¸/ì¬ê°œ/ì¤‘ë³µì œê±°/ì¦ë¶„ì €ì¥) ----------\n",
    "def run_collect():\n",
    "    # ê¸°ì¡´ íŒŒì¼ì—ì„œ seen/ since_id ë¡œë“œ\n",
    "    seen, since_id = load_existing_ids(OUTPUT_JSONL)\n",
    "    print(f\"ğŸ“‚ resume: existing={len(seen)} rows, since_id={since_id}\")\n",
    "\n",
    "    collected = 0\n",
    "    buffer_jsonl: List[Dict] = []\n",
    "    buffer_csv:   List[Dict] = []\n",
    "\n",
    "    try:\n",
    "        for row in search_recent_generator(\n",
    "            query=QUERY,\n",
    "            start_time=START_TIME,\n",
    "            end_time=END_TIME,\n",
    "            page_size=PAGE_SIZE,\n",
    "            since_id=since_id,\n",
    "        ):\n",
    "            tid = row[\"id\"]\n",
    "            if tid in seen:\n",
    "                continue\n",
    "            seen.add(tid)\n",
    "            buffer_jsonl.append(row)\n",
    "            buffer_csv.append(row)\n",
    "            collected += 1\n",
    "\n",
    "            # ---- ë°°ì¹˜ ì €ì¥(ë©”ëª¨ë¦¬ ê³¼ì  ë°©ì§€ + ì²´í¬í¬ì¸íŠ¸) ----\n",
    "            if len(buffer_jsonl) >= 200:\n",
    "                append_jsonl(OUTPUT_JSONL, buffer_jsonl)\n",
    "                append_csv(OUTPUT_CSV, buffer_csv)\n",
    "                print(f\"ğŸ’¾ saved +{len(buffer_jsonl)} (total={collected})\")\n",
    "                buffer_jsonl.clear()\n",
    "                buffer_csv.clear()\n",
    "\n",
    "            # ---- ìˆ˜ì§‘ ìƒí•œ ----\n",
    "            if collected >= MAX_TWEETS_TOTAL:\n",
    "                print(f\"âœ… reached MAX_TWEETS_TOTAL={MAX_TWEETS_TOTAL}\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"ğŸ›‘ ì‚¬ìš©ì ì¤‘ë‹¨ â†’ ë¶€ë¶„ ì €ì¥ ì‹¤í–‰\")\n",
    "\n",
    "    finally:\n",
    "        # ë‚¨ì€ ë²„í¼ ì €ì¥\n",
    "        if buffer_jsonl:\n",
    "            append_jsonl(OUTPUT_JSONL, buffer_jsonl)\n",
    "            append_csv(OUTPUT_CSV, buffer_csv)\n",
    "            print(f\"ğŸ’¾ saved (final flush) +{len(buffer_jsonl)}\")\n",
    "        print(f\"ğŸ‰ done. total collected in this run: {collected}\")\n",
    "\n",
    "run_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe70321-443a-490b-bc48-293311f1ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨: Unexpected character found when decoding 'true'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ysu13\\AppData\\Local\\Temp\\ipykernel_23532\\459154607.py:3: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(OUTPUT_JSONL, lines=True)\n"
     ]
    }
   ],
   "source": [
    "# ---------- 5) ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° ----------\n",
    "try:\n",
    "    df = pd.read_json(OUTPUT_JSONL, lines=True)\n",
    "    print(\"ì´ í–‰:\", len(df))\n",
    "    display(df.head(5)[[\"date\",\"username\",\"text\"]])\n",
    "except Exception as e:\n",
    "    print(\"ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1cd5a6-f571-43f9-87e1-21969510e247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ 429 TooManyRequests\n",
      " â†’ ì œí•œ í•´ì œ ì˜ˆìƒ(UTC): 2025-10-14 10:58:07+00:00 (ì•½ 876ì´ˆ í›„)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy, os, time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "BEARER_TOKEN = BEARER_TOKEN  # ê¸°ì¡´ ë³€ìˆ˜ ì¬ì‚¬ìš©\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=False)\n",
    "\n",
    "def one_shot_probe():\n",
    "    try:\n",
    "        # ê°€ì¥ ê°€ë²¼ìš´ ìš”ì²­: ìµœê·¼ ê²€ìƒ‰ 1í˜ì´ì§€(10ê°œ), end/start ìƒëµ\n",
    "        resp = client.search_recent_tweets(\n",
    "            query='(\"ê²½ì œ ë‰´ìŠ¤ ì–´ë µë‹¤\" OR \"ê²½ì œ ê¸°ì‚¬ ì–´ë µë‹¤\") lang:ko -is:retweet',\n",
    "            max_results=10,\n",
    "            tweet_fields=[\"created_at\"]\n",
    "        )\n",
    "        # TweepyëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í—¤ë”ë¥¼ ì•ˆ ë‚´ë³´ë‚´ì§€ë§Œ, ì—ëŸ¬ ì‹œì—” ì˜ˆì™¸ë¡œ í™•ì¸\n",
    "        print(\"âœ… probe status: OK\")\n",
    "        print(\"data count:\", 0 if not resp.data else len(resp.data))\n",
    "        if resp.data:\n",
    "            print(\"sample:\", resp.data[0].text[:80])\n",
    "        return True\n",
    "    except tweepy.Unauthorized as e:\n",
    "        print(\"âŒ 401 Unauthorized â†’ Bearer Token í™•ì¸ í•„ìš”\")\n",
    "        return False\n",
    "    except tweepy.TooManyRequests as e:\n",
    "        # ë‚¨ì€ ì‹œê°„ ê³„ì‚°(ê°€ëŠ¥í•˜ë©´ í—¤ë”ì—ì„œ reset ì½ê¸°)\n",
    "        headers = getattr(e.response, \"headers\", {})\n",
    "        reset = headers.get(\"x-rate-limit-reset\")\n",
    "        print(\"âš ï¸ 429 TooManyRequests\")\n",
    "        if reset:\n",
    "            reset_dt = datetime.fromtimestamp(int(reset), tz=timezone.utc)\n",
    "            wait_sec = (reset_dt - datetime.now(timezone.utc)).total_seconds()\n",
    "            print(f\" â†’ ì œí•œ í•´ì œ ì˜ˆìƒ(UTC): {reset_dt} (ì•½ {int(wait_sec)}ì´ˆ í›„)\")\n",
    "        else:\n",
    "            print(\" â†’ reset í—¤ë” ì—†ìŒ: ëª‡ ë¶„ ë’¤ ì¬ì‹œë„\")\n",
    "        return False\n",
    "    except tweepy.BadRequest as e:\n",
    "        print(\"âŒ 400 BadRequest â†’ ì‹œê°„ íŒŒë¼ë¯¸í„° ë“± í™•ì¸ í•„ìš”\")\n",
    "        print(e)\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Unexpected:\", repr(e))\n",
    "        return False\n",
    "\n",
    "one_shot_probe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720420a-c248-447c-8bae-8d6f69caf6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3402a1-c864-4b6d-b6e2-c3b103e3f120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb50bb-3027-4345-bf8e-c1ae08323cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b908b1-64ee-4e3c-812a-93251912f5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014f52c-155c-4197-add6-29a0a443c0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633fbc2-4012-4722-abc7-a55640204d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d842778-117e-40d7-98dd-56e9a589c24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4f8e2-c28b-447e-9cc5-ba900e18081a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
